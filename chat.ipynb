{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHuYRB2mly1y+hByH+JWXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jotalian/projeto_inicial/blob/main/chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "vRXFNXhk13sc",
        "outputId": "2722ea57-c63f-4fac-dcf2-d753beca2ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Recursos do Google para Aprendizado de IA**\n",
            "\n",
            "**Cursos online:**\n",
            "\n",
            "* [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course)\n",
            "* [TensorFlow Coursera Specialization](https://www.coursera.org/specializations/tensorflow-in-practice)\n",
            "* [AI Platform Specialization](https://www.coursera.org/specializations/ai-platform)\n",
            "\n",
            "**Cursos práticos na plataforma Coursera:**\n",
            "\n",
            "* [Introdução à Aprendizagem de Máquina](https://www.coursera.org/specializations/machine-learning)\n",
            "* [Técnicas Avançadas de Aprendizagem de Máquina](https://www.coursera.org/specializations/advanced-machine-learning)\n",
            "* [Aprendizado Profundo](https://www.coursera.org/specializations/deep-learning)\n",
            "\n",
            "**Documentação e guias:**\n",
            "\n",
            "* [TensorFlow](https://www.tensorflow.org/)\n",
            "* [Keras](https://keras.io/)\n",
            "* [Google Cloud AI Platform](https://cloud.google.com/ai-platform/)\n",
            "\n",
            "**Workshops e webinars:**\n",
            "\n",
            "* [Eventos e Workshops do Google Cloud AI](https://cloud.google.com/ai/events)\n",
            "* [Webinars do TensorFlow](https://www.tensorflow.org/community/webinars)\n",
            "\n",
            "**Comunidades e fóruns:**\n",
            "\n",
            "* [Comunidade do TensorFlow](https://www.tensorflow.org/community/)\n",
            "* [Fórum de IA do Google](https://groups.google.com/g/ai-platform-questions)\n",
            "\n",
            "**Experiências para iniciantes:**\n",
            "\n",
            "* [TensorFlow Playground](https://playground.tensorflow.org/)\n",
            "* [Quick, Draw! with TensorFlow](https://quickdraw.withgoogle.com/)\n",
            "* [Teachable Machine](https://teachablemachine.withgoogle.com/)\n",
            "\n",
            "**Recursos adicionais:**\n",
            "\n",
            "* [Google AI Blog](https://blog.google/technology/ai/)\n",
            "* [Canal do YouTube do Google AI](https://www.youtube.com/channel/UCEe_m55s82h1uHKL_0R6hXA)\n",
            "* [GitHub da Equipe de Pesquisa do Google](https://github.com/google-research)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('SECRET_KEY')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "response = model.generate_content('Aprendendo Ia com o Google. Me de sugestões.')\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Generation_Config ={\n",
        "    'candidate_count': 1,\n",
        "    'temperature': 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "I7tvhf3sBG-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content('Aprendendo Ia com o Google. Me de atualizações.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "jlY-adDmD76X",
        "outputId": "f3efac08-eede-49dd-934b-2bf4b1af5ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Atualizações de Aprendizado de Máquina (IA) do Google**\n",
            "\n",
            "**Lançamento do BLOOM** (2023)\n",
            "* O maior modelo de linguagem multimodal já treinado, com mais de 176 bilhões de parâmetros.\n",
            "* Capaz de tarefas avançadas como geração de texto, tradução e compreensão da linguagem natural.\n",
            "\n",
            "**Integração do AI Test Kitchen com o Google Drive** (2023)\n",
            "* Permite que os usuários testem e iterem modelos de IA diretamente no Drive.\n",
            "* Simplifica o desenvolvimento e implantação de projetos de IA.\n",
            "\n",
            "**Novos Recursos do Vertex AI** (2023)\n",
            "* Capacidades aprimoradas de treinamento e implantação de modelos.\n",
            "* Novos modelos pré-treinados para tarefas como processamento de linguagem natural e visão computacional.\n",
            "\n",
            "**Lançamento do LaMDA 2** (2023)\n",
            "* A segunda geração do modelo de linguagem LaMDA do Google.\n",
            "* Avanços significativos na geração de texto e compreensão da linguagem.\n",
            "\n",
            "**Parceria com o Meta** (2022)\n",
            "* Colaboração para desenvolver novos padrões e ferramentas de IA.\n",
            "* Foco em segurança, responsabilidade e equidade em sistemas de IA.\n",
            "\n",
            "**Aquisição da Anthropic** (2023)\n",
            "* Aquisição da empresa de pesquisa de IA.\n",
            "* Acesso às tecnologias de IA generativa líderes da Anthropic, como Gemini.\n",
            "\n",
            "**Iniciativas de Pesquisa**\n",
            "* Pesquisa contínua em processamento de linguagem natural, visão computacional e aprendizado profundo.\n",
            "* Foco no desenvolvimento de modelos de IA eficientes, confiáveis e equitativos.\n",
            "\n",
            "**Programas de Educação**\n",
            "* Lançamento da certificação Professional Machine Learning Engineer do Google.\n",
            "* Expansão do programa de treinamento Coursera para profissionais de IA.\n",
            "\n",
            "**Conclusão**\n",
            "\n",
            "O Google continua a investir pesadamente em IA, com atualizações e inovações constantes. Essas atualizações visam capacitar desenvolvedores, pesquisadores e empresas a criar e implantar soluções de IA avançadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "wciQYvCbGR7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace(\"<\", \"&lt;\")\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# Imprimindo o histórico\n",
        "for message in chat.history:\n",
        "    display(to_markdown(message.role + \": \" + message.parts[0].text))\n",
        "    print('-----------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b9O7utfOSE0s",
        "outputId": "e1c598f7-d1f7-438f-ce5a-cfe6f9cf6adf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: qual o menu brasileiro"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: **Entradas**\n> \n> * **Pão de queijo:** Pãezinhos salgados feitos com queijo minas\n> * **Coxinha:** Croquetes fritos recheados com frango, queijo ou presunto\n> * **Kibe:** Bolinhos de trigo recheados com carne moída\n> * **Empada:** Tortinhas assadas recheadas com frango, carne ou legumes\n> * **Pastel:** Pastéis fritos recheados com diversos sabores\n> \n> **Pratos Principais**\n> \n> **Carnes:**\n> \n> * **Feijoada:** Ensopado de feijão preto com carnes diversas\n> * **Churrasco:** Carnes grelhadas no espeto\n> * **Carne de sol:** Carne seca temperada e assada\n> * **Moqueca:** Ensopado de peixe ou frutos do mar\n> * **Picadinho:** Ensopado de carne moída com legumes\n> \n> **Aves e Peixes:**\n> \n> * **Frango à passarinho:** Frango frito em pedaços pequenos\n> * **Arroz de pato:** Arroz cozido com pato\n> * **Bacalhau à Gomes de Sá:** Bacalhau assado com batatas, cebolas e ovos\n> * **Salmão grelhado:** Salmão grelhado com legumes\n> * **Camarão na manteiga:** Camarões grelhados com manteiga\n> \n> **Pratos Vegetarianos:**\n> \n> * **Vatapá:** Ensopado de pão, camarão e leite de coco\n> * **Acarajé:** Bolinhos de feijão-fradinho fritos\n> * **Abóbora com carne seca:** Abóbora cozida com carne seca\n> * **Baião de dois:** Arroz com feijão de corda\n> * **Tapioca:** Pudim feito com polvilho de tapioca\n> \n> **Acompanhamentos**\n> \n> * **Arroz branco:** Arroz cozido simples\n> * **Feijão preto:** Feijão preto cozido\n> * **Farofa:** Farinha de mandioca torrada\n> * **Salada:** Folhas verdes com legumes diversos\n> * **Batata frita:** Batatas fritas\n> \n> **Sobremesas**\n> \n> * **Brigadeiro:** Docinhos de chocolate\n> * **Beijinho:** Docinhos de leite condensado com coco\n> * **Pudim de leite:** Pudim de leite condensado\n> * **Quindim:** Pudim de gemas\n> * **Mousse de maracujá:** Mousse de maracujá\n> \n> **Bebidas**\n> \n> * **Cachaça:** Bebida alcoólica destilada da cana-de-açúcar\n> * **Caipirinha:** Coquetel de cachaça, limão e açúcar\n> * **Guaraná:** Refrigerante à base de guaraná\n> * **Água de coco:** Água extraída do coco\n> * **Sucos de frutas:** Sucos naturais de frutas diversas"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: qual é o dizer do dia"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: **Dizer do dia: 27 de fevereiro de 2023**\n> \n> > \"A vida é como andar de bicicleta. Para manter o equilíbrio, você precisa continuar se movendo.\"\n> \n> **Autor:** Albert Einstein"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: quem com fogo"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: **Quem com fogo brinca com fogo se queima.**\n> \n> Este provérbio significa que quem se envolve em atividades perigosas ou arriscadas corre o risco de sofrer as consequências. É um aviso para que as pessoas sejam cautelosas e evitem colocar-se em situações que possam resultar em danos ou prejuízos.\n> \n> A origem do provérbio é incerta, mas é usado há séculos para ensinar as pessoas sobre a importância de tomar cuidado e evitar comportamentos imprudentes."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: relacao com gemini e alura"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: **Relação entre Gêmeos e Alura**\n> \n> **Gêmeos** é um signo de ar mutável, conhecido por sua inteligência, comunicação e versatilidade. **Alura** é uma plataforma online de educação que oferece cursos em diversas áreas, incluindo tecnologia, negócios e criatividade.\n> \n> A relação entre Gêmeos e Alura é muito positiva, pois ambos compartilham um amor pelo aprendizado e pela comunicação. Os geminianos são naturalmente curiosos e estão sempre ansiosos para expandir seus conhecimentos. A Alura oferece uma ampla gama de cursos que podem atender aos interesses variados dos geminianos.\n> \n> Além disso, os geminianos são excelentes comunicadores e podem facilmente articular suas ideias e pensamentos. Isso os torna alunos ideais para os cursos online da Alura, pois podem aprender no seu próprio ritmo e se comunicar facilmente com os instrutores e outros alunos.\n> \n> **Aqui estão alguns motivos específicos pelos quais Gêmeos e Alura são uma boa combinação:**\n> \n> * **Curiosidade intelectual:** Os geminianos são naturalmente curiosos e estão sempre em busca de novos conhecimentos. A Alura oferece uma ampla variedade de cursos que podem satisfazer a sede de conhecimento dos geminianos.\n> * **Versatilidade:** Os geminianos são versáteis e podem se adaptar facilmente a diferentes tópicos e disciplinas. A Alura oferece cursos em diversas áreas, permitindo que os geminianos explorem seus interesses variados.\n> * **Comunicação:** Os geminianos são excelentes comunicadores. Os cursos online da Alura oferecem oportunidades para os geminianos interagirem com instrutores e outros alunos, compartilhando ideias e aprendendo uns com os outros.\n> * **Flexibilidade:** Os cursos online da Alura são flexíveis e permitem que os alunos aprendam no seu próprio ritmo. Isso é ideal para os geminianos, que podem ser impacientes e preferem aprender em um ritmo acelerado.\n> \n> Em resumo, a relação entre Gêmeos e Alura é muito positiva. Os geminianos podem aproveitar a ampla gama de cursos da Alura para expandir seus conhecimentos, enquanto a Alura pode se beneficiar da curiosidade intelectual, versatilidade e habilidades de comunicação dos geminianos."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: qual a cor da agua"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: A água pura é **incolor**, ou seja, não tem cor.\n> \n> No entanto, a água pode parecer colorida devido a impurezas, substâncias dissolvidas ou condições de iluminação. Por exemplo:\n> \n> * A água do mar pode parecer azul ou verde devido à absorção e dispersão da luz solar.\n> * A água de lagos e rios pode parecer marrom ou verde devido à presença de sedimentos, algas ou matéria orgânica.\n> * A água com cloro pode parecer azul claro devido à adição de produtos químicos.\n> * A água sob luz artificial pode parecer amarela ou âmbar.\n> \n> Em resumo, a água pura é incolor, mas pode parecer colorida devido a fatores externos."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: ok"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: Claro. Se você tiver mais alguma dúvida ou precisar de ajuda com algo, não hesite em perguntar. Estou aqui para ajudá-lo."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: sair"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: Obrigado por usar meus serviços. Estou sempre aqui se você precisar de ajuda no futuro.\n> \n> Até a próxima! 👋"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: qual o caminho mais curto"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: **O caminho mais curto** é a distância mais direta entre dois pontos.\n> \n> Para encontrar o caminho mais curto entre dois pontos em um mapa ou em um aplicativo de GPS, você pode usar a ferramenta de **rota**. Esta ferramenta calcula a distância e o tempo estimado para percorrer a rota mais eficiente entre os pontos de partida e de chegada.\n> \n> **Aqui estão os passos gerais para encontrar o caminho mais curto:**\n> \n> 1. Abra um aplicativo de mapas ou GPS (como Google Maps ou Waze).\n> 2. Digite os endereços ou nomes dos locais de partida e de chegada.\n> 3. Clique no botão \"Rota\" ou \"Direções\".\n> 4. O aplicativo calculará a rota mais curta e exibirá as instruções passo a passo.\n> \n> **Fatores que podem afetar o caminho mais curto:**\n> \n> * **Trânsito:** O aplicativo de GPS levará em consideração as condições de trânsito em tempo real para encontrar a rota mais rápida.\n> * **Tipo de veículo:** Alguns aplicativos de GPS permitem que você especifique o tipo de veículo que você está dirigindo, o que pode afetar o caminho mais curto (por exemplo, caminhões podem ter restrições de rota).\n> * **Preferências:** Alguns aplicativos de GPS permitem que você defina preferências, como evitar rodovias ou pedágios, o que pode alterar o caminho mais curto.\n> \n> **Observações:**\n> \n> * O caminho mais curto nem sempre é o mais rápido, especialmente durante os horários de pico.\n> * Se você estiver viajando a pé ou de bicicleta, o caminho mais curto pode não ser o mais conveniente ou seguro.\n> * É sempre recomendável verificar as condições de trânsito e as instruções da rota antes de iniciar sua viagem."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: sair"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: Obrigado por usar meus serviços. Estou sempre aqui se você precisar de ajuda no futuro.\n> \n> Até a próxima! 👋"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: qual o caminho mais obvio"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: **O caminho mais óbvio** é aquele que é mais fácil de ver ou perceber, geralmente porque é o mais direto ou o mais lógico.\n> \n> Em outras palavras, é o caminho que a maioria das pessoas escolheria sem precisar pensar muito.\n> \n> **Aqui estão alguns exemplos de caminhos óbvios:**\n> \n> * O caminho mais curto entre dois pontos em um mapa\n> * A rota principal para chegar a uma cidade\n> * A porta de entrada de um prédio\n> * O botão liga/desliga de um dispositivo\n> * A opção padrão em um menu\n> \n> **Fatores que podem tornar um caminho óbvio:**\n> \n> * **Percepção visual:** O caminho é fácil de ver e seguir.\n> * **Experiência anterior:** As pessoas estão familiarizadas com o caminho e sabem que ele leva ao destino desejado.\n> * **Conveniência:** O caminho é conveniente e fácil de percorrer.\n> * **Lógica:** O caminho faz sentido e parece ser a escolha mais razoável.\n> \n> **Observações:**\n> \n> * Nem sempre o caminho mais óbvio é o melhor caminho. Pode haver caminhos alternativos que são mais rápidos, mais eficientes ou mais seguros.\n> * O que é óbvio para uma pessoa pode não ser óbvio para outra.\n> * Às vezes, é necessário pensar fora da caixa e considerar caminhos menos óbvios para encontrar a melhor solução."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: sair"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: Obrigado por usar meus serviços. Estou sempre aqui se você precisar de ajuda no futuro.\n> \n> Até a próxima! 👋"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> user: fim"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> model: Obrigado por usar meus serviços. Estou sempre aqui se precisar de ajuda no futuro.\n> \n> **Até a próxima!** 👋"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input ('Iniciando Conversa: ')\n",
        "while prompt != 'Sair' == 'sair' == 'Ok' == 'ok':\n",
        "  response = chat.send_message(prompt)\n",
        "  print('Resposta: ', response.text, '\\n')\n",
        "  prompt = input ('Iniciando Conversa: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNRN9stCIJSw",
        "outputId": "487724bb-ffcd-4082-95c1-25d78225d5a8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando Conversa: ok\n"
          ]
        }
      ]
    }
  ]
}